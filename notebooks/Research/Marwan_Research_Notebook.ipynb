{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numeric Features\n",
    "The youtube datasets presents a variety of numeric variables. These variables and their relationship with the number of days a video remains on the trending page, as well as the number of days a video takes to reach the trending page.\n",
    "\n",
    "The variables given in the dataset which will be considered in this section are:\n",
    "\n",
    "- Views\n",
    "- Likes\n",
    "- Dislikes\n",
    "- Publish Date\n",
    "- Publish Time\n",
    "- Trending Date \n",
    "- Category\n",
    "\n",
    "\n",
    "## Motivation\n",
    "Our motivation regarding this section is to understand which of the variables listed above are considered by youtube's algorithm, and to identify - given these features - if it is possible to predict how soon after being published a video will reach trending, and once it reaches trending how long it will remain trending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "%matplotlib notebook\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "\n",
    "\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import random\n",
    "import operator\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\n",
    "from statistics import *\n",
    "import concurrent.futures\n",
    "import time\n",
    "#import pyLDAvis.sklearn\n",
    "from pylab import bone, pcolor, colorbar, plot, show, rcParams, savefig\n",
    "import warnings\n",
    "import nltk\n",
    "\n",
    "\n",
    "# spaCy based imports\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# keras module for building LSTM \n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "#from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "#from keras.preprocessing.text import Tokenizer\n",
    "#from keras.callbacks import EarlyStopping\n",
    "#from keras.models import Sequential\n",
    "#import keras.utils as ku \n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.utils as ku\n",
    "# set seeds for reproducability\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENG_df = pd.read_csv('../../data/data.csv')\n",
    "\n",
    "#Publish_time column contains date and time together, first I will get the correct format.\n",
    "ENG_df['publish_time'] = pd.to_datetime(ENG_df['publish_time'], errors='coerce', format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "#Removing any null values\n",
    "ENG_df = ENG_df[ENG_df['trending_date'].notnull()]\n",
    "ENG_df = ENG_df[ENG_df['publish_time'].notnull()]\n",
    "\n",
    "#Separating previous publish_time column into two separate columns, publish date and publish time. \n",
    "ENG_df.insert(4, 'publish_date', ENG_df['publish_time'].dt.date)\n",
    "ENG_df['publish_time'] = ENG_df['publish_time'].dt.time\n",
    "\n",
    "#splitting publish_time column into separate hour, minute and second columns\n",
    "ENG_df['publish_time'] = ENG_df['publish_time'].astype(str)\n",
    "ENG_df[['hour','minute','second']] = ENG_df.publish_time.str.split(\":\", expand=True).astype(int)\n",
    "\n",
    "#Adding like_rate, dislike_rate and comment_rate features to observe. I expect there to be a relationship between these features\n",
    "#and time to reach trending, as well as time remained on trending. \n",
    "#These features represent viewer engagement, what percentage of viewers actually like, dislike and/or comment on the videos.\n",
    "ENG_df['like_rate'] = ENG_df['likes']/ENG_df['views']*100\n",
    "ENG_df['dislike_rate'] = ENG_df['dislikes']/ENG_df['views']*100\n",
    "ENG_df['comment_rate'] = ENG_df['comment_count']/ENG_df['views']*100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_init = ENG_df[ENG_df['country']== 'Country.us']\n",
    "GB_init = ENG_df[ENG_df['country']== 'Country.gb']\n",
    "CA_init = ENG_df[ENG_df['country']== 'Country.ca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Addingn columns into each region's dataframe which represents the number of days a video remains trending. \n",
    "occurances_US = US_init.groupby(['video_id']).size()\n",
    "days_trending_US = occurances_US.to_frame(name = 'days_trending').reset_index()\n",
    "\n",
    "US = pd.merge(left=US_init, right=days_trending_US, left_on='video_id', right_on='video_id', how='outer')\n",
    "\n",
    "occurances_GB = GB_init.groupby(['video_id']).size()\n",
    "days_trending_GB = occurances_GB.to_frame(name = 'days_trending').reset_index()\n",
    "\n",
    "GB = pd.merge(left=GB_init, right=days_trending_GB, left_on='video_id', right_on='video_id', how='outer')\n",
    "\n",
    "occurances_CA = CA_init.groupby(['video_id']).size()\n",
    "days_trending_CA = occurances_CA.to_frame(name = 'days_trending').reset_index()\n",
    "\n",
    "CA = pd.merge(left=CA_init, right=days_trending_CA, left_on='video_id', right_on='video_id', how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframes which consist of the first occurance of a video on trending, \n",
    "#as well as one for a video's last occurence on trending\n",
    "US_last = US.drop_duplicates(['video_id'], keep='last')\n",
    "US_first = US.drop_duplicates(['video_id'], keep='first')\n",
    "\n",
    "GB_last = GB.drop_duplicates(['video_id'], keep='last')\n",
    "GB_first = GB.drop_duplicates(['video_id'], keep='first')\n",
    "\n",
    "CA_last = CA.drop_duplicates(['video_id'], keep='last')\n",
    "CA_first = CA.drop_duplicates(['video_id'], keep='first')\n",
    "\n",
    "#US.set_index(['trending_date','video_id'], inplace= True)\n",
    "#US.set_index(['trending_date', 'video_id'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection and Scoring\n",
    "\n",
    "Now I will use sklearn's SelectKBest features on each region's dataset respectively. I will be considering, like rate, comment rate, dislike rate, hour, minute and second published. I will be assessing their applicability to days trending. Additionally, I will observe whether the number of views a video has on it's first occurance on trending is a valid predictor to the number of days a video remains on trending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beginning with the US dataset. Considering the features regarding a video on it's first occurence on trending. \n",
    "#selecting features to consider for X_first as: views, like_rate, dislike_rate, comment_count, hour of publish, minute of publish and second of publish.\n",
    "X_US_first = US_first.iloc[:,[8,22,23,24,19,20,21]]\n",
    "y_US_first = US_first.iloc[:,-1]\n",
    "\n",
    "X_GB_first = GB_first.iloc[:,[8,22,23,24,19,20,21]]\n",
    "y_GB_first = GB_first.iloc[:,-1]\n",
    "\n",
    "X_CA_first = CA_first.iloc[:,[8,22,23,24,19,20,21]]\n",
    "y_CA_first = CA_first.iloc[:,-1]\n",
    "\n",
    "X_US_last = US_last.iloc[:,[22,23,24,19,20,21]]\n",
    "Y_US_last = US_last.iloc[:,-1]\n",
    "\n",
    "X_GB_last = GB_last.iloc[:,[22,23,24,19,20,21]]\n",
    "Y_GB_last = GB_last.iloc[:,-1]\n",
    "\n",
    "X_CA_last = CA_last.iloc[:,[22,23,24,19,20,21]]\n",
    "Y_CA_last = CA_last.iloc[:,-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consideration of numeric features vs days trending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US_first scores\n",
      "       Variable     Score\n",
      "4          hour  0.095078\n",
      "1     like_rate  0.062591\n",
      "0         views  0.052806\n",
      "3  comment_rate  0.044677\n",
      "2  dislike_rate  0.035275\n",
      "5        minute  0.000000\n",
      "6        second  0.000000\n"
     ]
    }
   ],
   "source": [
    "US_first_selector = SelectKBest(score_func=mutual_info_regression, k=5)\n",
    "US_first_new = US_first_selector.fit_transform(X_US_first, y_US_first)\n",
    "#print(US_first_new[:5])\n",
    "#print(X_US_first)\n",
    "\n",
    "scores_US_first = pd.DataFrame({'Variable' : X_US_first.columns, 'Score': US_first_selector.scores_})\n",
    "#pvalue_US_first = pd.DataFrame({'Variable' : X_US_first.columns, 'p values' : US_first_selector.pvalues_})\n",
    "\n",
    "print(\"US_first scores\")\n",
    "print(scores_US_first.sort_values(by=['Score'], ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the best 5 features from the US dataset, the scores_ show that the best features to consider on the first occurance of a video on the trending page in order to predict the number of days it will remain trending are:\n",
    "1. Hour uploaded\n",
    "2. Like rate\n",
    "3. Views\n",
    "4. Comment rate\n",
    "5. Dislike rate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB_first scores\n",
      "       Variable     Score\n",
      "4          hour  0.077069\n",
      "3  comment_rate  0.076039\n",
      "1     like_rate  0.076016\n",
      "2  dislike_rate  0.035719\n",
      "0         views  0.029989\n",
      "5        minute  0.024866\n",
      "6        second  0.016916\n"
     ]
    }
   ],
   "source": [
    "GB_first_selector = SelectKBest(score_func=mutual_info_regression, k=5)\n",
    "GB_first_new = GB_first_selector.fit_transform(X_GB_first, y_GB_first)\n",
    "#print(US_first_new[:5])\n",
    "#print(X_US_first)\n",
    "\n",
    "scores_GB_first = pd.DataFrame({'Variable' : X_GB_first.columns, 'Score': GB_first_selector.scores_})\n",
    "#pvalue_US_first = pd.DataFrame({'Variable' : X_US_first.columns, 'p values' : US_first_selector.pvalues_})\n",
    "print(\"GB_first scores\")\n",
    "print(scores_GB_first.sort_values(by=['Score'], ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the best 5 features from the GB dataset, the scores_ show that the best features to consider on the first occurance of a video on the trending page in order to predict the number of days it will remain trending are:\n",
    "1. Hour uploaded\n",
    "2. Comment rate\n",
    "3. Like rate\n",
    "3. Dislike rate\n",
    "4. Views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA_first scores\n",
      "       Variable     Score\n",
      "4          hour  0.165783\n",
      "3  comment_rate  0.027797\n",
      "0         views  0.019604\n",
      "1     like_rate  0.014241\n",
      "6        second  0.009868\n",
      "2  dislike_rate  0.007721\n",
      "5        minute  0.005007\n"
     ]
    }
   ],
   "source": [
    "CA_first_selector = SelectKBest(score_func=mutual_info_regression, k=5)\n",
    "CA_first_new = CA_first_selector.fit_transform(X_CA_first, y_CA_first)\n",
    "\n",
    "\n",
    "scores_CA_first = pd.DataFrame({'Variable' : X_CA_first.columns, 'Score': CA_first_selector.scores_})\n",
    "#pvalue_US_first = pd.DataFrame({'Variable' : X_US_first.columns, 'p values' : US_first_selector.pvalues_})\n",
    "print(\"CA_first scores\")\n",
    "print(scores_CA_first.sort_values(by=['Score'], ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the best 5 features from the CA dataset, the scores_ show that the best features to consider on the first occurance of a video on the trending page in order to predict the number of days it will remain trending are:\n",
    "1. Hour uploaded\n",
    "2. Comment rate\n",
    "3. Views\n",
    "3. Like rate\n",
    "4. Second uploaded \n",
    "\n",
    "It definitely holds up to the polite canadian stereotype that dislike_rate is not even in the best 5 features! :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Next I will perform the same feature selection on the last occurence of a video on the trending page. As a result of it being the last occurrence on trending, I will mitigate the views feature from selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Variable     Score\n",
      "4        minute  0.025132\n",
      "0     like_rate  0.019735\n",
      "1  dislike_rate  0.012333\n",
      "2  comment_rate  0.006312\n",
      "3          hour  0.000396\n",
      "5        second  0.000000\n"
     ]
    }
   ],
   "source": [
    "US_last_selector = SelectKBest(score_func=mutual_info_regression, k=5)\n",
    "US_last_new = US_last_selector.fit_transform(X_US_last, Y_US_last)\n",
    "\n",
    "US_scores_last = pd.DataFrame({'Variable' : X_US_last.columns, 'Score': US_last_selector.scores_})\n",
    "\n",
    "print(US_scores_last.sort_values(by=['Score'], ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the last occurrence of a video on trending from the US, the 5 best selected features were:\n",
    "\n",
    "1. Minute of upload\n",
    "2. Like rate\n",
    "3. Dislike rate\n",
    "4. Comment rate\n",
    "5. Hour uploaded\n",
    "\n",
    "However, the scores are extremely low for all predictors which is indicative of a large amount of noise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Variable     Score\n",
      "4        minute  0.029820\n",
      "3          hour  0.024951\n",
      "1  dislike_rate  0.009726\n",
      "5        second  0.009420\n",
      "2  comment_rate  0.007655\n",
      "0     like_rate  0.006376\n"
     ]
    }
   ],
   "source": [
    "GB_last_selector = SelectKBest(score_func=mutual_info_regression, k=5)\n",
    "GB_last_new = GB_last_selector.fit_transform(X_GB_last, Y_GB_last)\n",
    "\n",
    "GB_scores_last = pd.DataFrame({'Variable' : X_GB_last.columns, 'Score': GB_last_selector.scores_})\n",
    "\n",
    "print(GB_scores_last.sort_values(by=['Score'], ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the last occurrence of a video on trending from GB, the 5 best selected features were:\n",
    "\n",
    "1. Minute of upload\n",
    "2. Hour uploaded\n",
    "3. Dislike rate\n",
    "4. Second uploaded\n",
    "5. Comment rate\n",
    "\n",
    "However, the scores are extremely low for all predictors which is indicative of a large amount of noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Variable     Score\n",
      "0     like_rate  0.022859\n",
      "2  comment_rate  0.009069\n",
      "3          hour  0.006022\n",
      "1  dislike_rate  0.003319\n",
      "5        second  0.002994\n",
      "4        minute  0.000488\n"
     ]
    }
   ],
   "source": [
    "CA_last_selector = SelectKBest(score_func=mutual_info_regression, k=5)\n",
    "CA_last_new = CA_last_selector.fit_transform(X_CA_last, Y_CA_last)\n",
    "\n",
    "CA_scores_last = pd.DataFrame({'Variable' : X_CA_last.columns, 'Score': CA_last_selector.scores_})\n",
    "\n",
    "print(CA_scores_last.sort_values(by=['Score'], ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the last occurrence of a video on trending from CA, the 5 best selected features were:\n",
    "\n",
    "1. Like rate\n",
    "2. Comment rate\n",
    "3. Hour uploaded\n",
    "4. Dislike rate\n",
    "5. Second uploaded\n",
    "\n",
    "However, the scores are extremely low for all predictors which is indicative of a large amount of noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the publish date and trending date columns to datetime format, so I can calculate time delta for days_to_trending.\n",
    "#US dataframe first\n",
    "US_first['publish_date'] = pd.to_datetime(US_first['publish_date'])\n",
    "US_first['trending_date'] = pd.to_datetime(US_first['trending_date'], format=\"%y.%d.%m\")\n",
    "US_first['days_to_trending'] = (US_first['trending_date'] - US_first['publish_date'])\n",
    "US_first['days_to_trending'] = US_first['days_to_trending'].dt.days.astype(int)\n",
    "\n",
    "#GB dataframe\n",
    "GB_first['publish_date'] = pd.to_datetime(GB_first['publish_date'])\n",
    "GB_first['trending_date'] = pd.to_datetime(GB_first['trending_date'], format=\"%y.%d.%m\")\n",
    "GB_first['days_to_trending'] = (GB_first['trending_date'] - GB_first['publish_date'])\n",
    "GB_first['days_to_trending'] = GB_first['days_to_trending'].dt.days.astype(int)\n",
    "\n",
    "#CA dataframe\n",
    "CA_first['publish_date'] = pd.to_datetime(CA_first['publish_date'])\n",
    "CA_first['trending_date'] = pd.to_datetime(CA_first['trending_date'], format=\"%y.%d.%m\")\n",
    "CA_first['days_to_trending'] = (CA_first['trending_date'] - CA_first['publish_date'])\n",
    "CA_first['days_to_trending'] = CA_first['days_to_trending'].dt.days.astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consideration of days taken to reach the trending page\n",
    "\n",
    "Next I consider the potential relationship between the time taken for a video to reach trending and the days it remains on trending. I will simply add this as a feature to X_diff, and perform the same SelectKBest feature selection as above, selecting the best 5 features, to see how this new feature scores amongst the previously selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features considered are, hour, minute, second, like rate, dislike rate, comment rate, days to trending\n",
    "X_US_diff = US_first.iloc[:,[19,20,21,22,23,24,26]]\n",
    "#target is still days_trending\n",
    "y_US_diff = US_first.iloc[:,25]\n",
    "\n",
    "X_GB_diff = GB_first.iloc[:,[19,20,21,22,23,24,26]]\n",
    "y_GB_diff = GB_first.iloc[:,25]\n",
    "\n",
    "X_CA_diff = CA_first.iloc[:,[19,20,21,22,23,24,26]]\n",
    "y_CA_diff = CA_first.iloc[:,25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Variable     Score\n",
      "6  days_to_trending  0.095979\n",
      "3         like_rate  0.047504\n",
      "5      comment_rate  0.032055\n",
      "4      dislike_rate  0.016808\n",
      "1            minute  0.014406\n",
      "0              hour  0.007897\n",
      "2            second  0.002456\n"
     ]
    }
   ],
   "source": [
    "US_diff_selector = SelectKBest(score_func=mutual_info_regression, k=5)\n",
    "US_diff_new = US_diff_selector.fit_transform(X_US_diff, y_US_diff)\n",
    "\n",
    "US_diff_scores = pd.DataFrame({'Variable' : X_US_diff.columns, 'Score': US_diff_selector.scores_})\n",
    "\n",
    "print(US_diff_scores.sort_values(by=['Score'], ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the US dataset, and introducing the consideration of the feature days_to_trending, the bset 5 features are:\n",
    "1. days_to_trending\n",
    "2. Like rate\n",
    "3. Comment rate\n",
    "4. Dislike rate\n",
    "5. Minute uploaded\n",
    "\n",
    "This shows that, in the US dataset, days_to_trending is the best predictor out of all the numerical values, for how long a video will remain trending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Variable     Score\n",
      "3         like_rate  0.025914\n",
      "5      comment_rate  0.010425\n",
      "1            minute  0.007495\n",
      "4      dislike_rate  0.007286\n",
      "0              hour  0.006297\n",
      "6  days_to_trending  0.004991\n",
      "2            second  0.000000\n"
     ]
    }
   ],
   "source": [
    "CA_diff_selector = SelectKBest(score_func=mutual_info_regression, k=5)\n",
    "CA_diff_new = CA_diff_selector.fit_transform(X_CA_diff, y_CA_diff)\n",
    "\n",
    "CA_diff_scores = pd.DataFrame({'Variable' : X_CA_diff.columns, 'Score': CA_diff_selector.scores_})\n",
    "\n",
    "print(CA_diff_scores.sort_values(by=['Score'], ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the CA dataset, and introducing the consideration of the feature days_to_trending, the bset 5 features are:\n",
    "1. Like rate\n",
    "2. Comment rate\n",
    "3. Minute uploaded\n",
    "4. Dislike rate\n",
    "5. Hour uploaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Variable     Score\n",
      "6  days_to_trending  0.162844\n",
      "3         like_rate  0.033257\n",
      "1            minute  0.031215\n",
      "2            second  0.028924\n",
      "4      dislike_rate  0.012332\n",
      "5      comment_rate  0.010969\n",
      "0              hour  0.005726\n"
     ]
    }
   ],
   "source": [
    "GB_diff_selector = SelectKBest(score_func=mutual_info_regression, k=5)\n",
    "GB_diff_new = GB_diff_selector.fit_transform(X_GB_diff, y_GB_diff)\n",
    "\n",
    "GB_diff_scores = pd.DataFrame({'Variable' : X_GB_diff.columns, 'Score': GB_diff_selector.scores_})\n",
    "\n",
    "print(GB_diff_scores.sort_values(by=['Score'], ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the CA dataset, and introducing the consideration of the feature days_to_trending, the bset 5 features are:\n",
    "1. days_to_trending\n",
    "2. Like rate\n",
    "3. Minute uploaded\n",
    "4. Second uploaded\n",
    "5. Dislike rate\n",
    "\n",
    "Once again, the best predictor as to how long a video will trend, in the GB dataset, is days_to_trending. The score assigned to this feature is significantly greater than all other features considered.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above feature selection showed that for the US and for GB, days_to_trending was the strongest predictor for the number of days a video remains on trending. This did not seem to be the case for the CA dataset, however. \n",
    "\n",
    "\n",
    "I have ignored number of likes and views despite their higher scores due to the fact that the DataFrame consisted only of the first entry of each video. The number of views a video has when it first appears on trending has nothing to do with predicting whether or not it reaches trending because this can only be known after the fact. However, like rate, comment rate, dislike rate and hour uploaded can all be observed prior to the first appearance of a video on the trending page, and can therefore give a better idea to the content creater how their video is performing relative to previous videos which appeared on trending. \n",
    "\n",
    "I believe that, given more data prior to the initial trending date, if we were able to observe the rate of increase of views, that would be an important feature to consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
